{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When Rotten Tomatoes Isn't Enough: Twitter Sentiment Analysis with DSE\n",
    "\n",
    "#### A demo using DataStax Enterprise Analytics, Apache Cassandra, Apache Spark, python, Jupyter Notebooks, pattern, and sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things To Setup\n",
    "* Install DSE https://docs.datastax.com/en/install/doc/install60/installTOC.html\n",
    "* Start DSE Analytics Cluster: dse cassandra -k #Must use -k option for Analytics\n",
    "* Using Python 2.7\n",
    "* Using DSE Analytics 6\n",
    "* Using latest verion of Jupyter\n",
    "* Install Anaconda and Jupyter #Anaconda is not required but will make installing jupyter easier \n",
    "* Find full path to <>/dse-6.0.1/resources/spark/python/lib/pyspark.zip\n",
    "* Find full path to <>/dse-6.0.1/resources/spark/python/lib/py4j-0.10.4-src.zip\n",
    "* Start Jupyter with DSE to get all environemnt variables: dse exec jupyter notebook\n",
    "* Make sure that the two CSV files are in the same locations as this notebook\n",
    "* !pip install cassandra-driver\n",
    "* !pip install pattern \n",
    "* !pip install panadas\n",
    "* Counter-intuitive don't install pyspark!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add some environment variables to find dse verision of pyspark. Edit these varibles with your path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pysparkzip = \"<>/dse-6.0.1/resources/spark/python/lib/pyspark.zip\"\n",
    "py4jzip = \"<>/dse-6.0.1/resources/spark/python/lib/py4j-0.10.4-src.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to be able to find pyspark libaries\n",
    "import sys\n",
    "sys.path.append(pysparkzip)\n",
    "sys.path.append(py4jzip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import python packages -- all are required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import cassandra\n",
    "import pyspark\n",
    "import re\n",
    "import os\n",
    "from IPython.display import display, Markdown\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer, StopWordsRemover\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pattern.en import sentiment, positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function to have nicer formatting of Spark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper for pretty formatting for Spark DataFrames\n",
    "def showDF(df, limitRows =  5, truncate = True):\n",
    "    if(truncate):\n",
    "        pandas.set_option('display.max_colwidth', 50)\n",
    "    else:\n",
    "        pandas.set_option('display.max_colwidth', -1)\n",
    "    pandas.set_option('display.max_rows', limitRows)\n",
    "    display(df.limit(limitRows).toPandas())\n",
    "    pandas.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Tables, Pulling Tweets, and Loading Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to DSE Analytics Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "\n",
    "cluster = Cluster(['127.0.0.1']) #If you have a locally installed DSE cluster\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Demo Keyspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS demo \n",
    "    WITH REPLICATION = \n",
    "    { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set keyspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.set_keyspace('demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Movie Title variable -- We are using Mission Impossible Fallout for this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieTitle = \"missionimpossible\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveNegative = [\"pos\", \"sad\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create two tables in Cassandra for the movie title. One of negative tweets and one for positive tweets. Twitter returns a lot of information with each call but for this demo we will just utilize the twitter id (as our Primary key as it is unique) and the actual tweet. \n",
    "#### Is using twitter id the right value to distriubte by? Consider your data model when choosing your primary key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emotion in positiveNegative: \n",
    "    \n",
    "    query = \"CREATE TABLE IF NOT EXISTS movie_tweets_%s_%s (twitterid bigint, tweet text, PRIMARY KEY (twitterid))\" % (movieTitle, emotion)\n",
    "    print query\n",
    "    session.execute(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Negative Tweets from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = open('sadTweets.csv', 'r')\n",
    "for line in input_file:\n",
    "    tweets = line.split(',')\n",
    "    query = \"INSERT INTO movie_tweets_%s_sad (twitterid, tweet)\" % (movieTitle)\n",
    "    query = query + \" VALUES (%s, %s)\"\n",
    "    session.execute(query, (int(tweets[0]), tweets[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Postive Tweets from CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file1 = open('posTweets.csv', 'r')\n",
    "for line in input_file1:\n",
    "    tweets = line.split(',')\n",
    "    query = \"INSERT INTO movie_tweets_%s_pos (twitterid, tweet)\" % (movieTitle)\n",
    "    query = query + \" VALUES (%s, %s)\"\n",
    "    session.execute(query, (int(tweets[0]), tweets[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do a select * on each table and verify that the tweets have been inserted into each Cassandra table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for emotion in positiveNegative:\n",
    "    print emotion\n",
    "    query = 'SELECT * FROM movie_tweets_%s_%s limit 10' % (movieTitle, emotion)\n",
    "    rows = session.execute(query)\n",
    "    for user_row in rows:\n",
    "        print (user_row.twitterid, user_row.tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally time for Apache Spark! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a spark session that is connected to Cassandra. From there load each table into a Spark Dataframe and take a count of the number of rows in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countTokens = udf(lambda words: len(words), IntegerType())\n",
    "\n",
    "spark = SparkSession.builder.appName('demo').master(\"local\").getOrCreate()\n",
    "\n",
    "tableNamePos = \"movie_tweets_%s_pos\" % (movieTitle.lower())\n",
    "tableNameSad = \"movie_tweets_%s_sad\" % (movieTitle.lower())\n",
    "tablepos = spark.read.format(\"org.apache.spark.sql.cassandra\").options(table=tableNamePos, keyspace=\"demo\").load()\n",
    "tablesad = spark.read.format(\"org.apache.spark.sql.cassandra\").options(table=tableNameSad, keyspace=\"demo\").load()\n",
    "\n",
    "print \"Postive Table Count: \"\n",
    "print tablepos.count()\n",
    "print \"Negative Table Count: \"\n",
    "print tablesad.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Tokenizer to break up the sentences into indiviudals words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizerPos = Tokenizer(inputCol=\"tweet\", outputCol=\"tweetwords\")\n",
    "tokenizedPos = tokenizerPos.transform(tablepos)\n",
    "\n",
    "dfPos = tokenizedPos.select(\"tweet\", \"tweetwords\").withColumn(\"tokens\", countTokens(col(\"tweetwords\")))\n",
    "\n",
    "showDF(dfPos)\n",
    "\n",
    "tokenizerSad = Tokenizer(inputCol=\"tweet\", outputCol=\"tweetwords\")\n",
    "tokenizedSad = tokenizerSad.transform(tablesad)\n",
    "\n",
    "dfSad = tokenizedSad.select(\"tweet\", \"tweetwords\").withColumn(\"tokens\", countTokens(col(\"tweetwords\")))\n",
    "\n",
    "showDF(dfSad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using StopWordsRemover to remove all stop words. Interesting to see, people don't use many stop words with twitter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removerPos = StopWordsRemover(inputCol=\"tweetwords\", outputCol=\"tweetnostopwords\")\n",
    "removedPos = removerPos.transform(dfPos)\n",
    "\n",
    "dfPosStop = removedPos.select(\"tweet\", \"tweetwords\", \"tweetnostopwords\").withColumn(\"tokens\", countTokens(col(\"tweetwords\"))).withColumn(\"notokens\", countTokens(col(\"tweetnostopwords\")))\n",
    "\n",
    "showDF(dfPosStop)\n",
    "\n",
    "removerSad = StopWordsRemover(inputCol=\"tweetwords\", outputCol=\"tweetnostopwords\")\n",
    "removedSad = removerSad.transform(dfSad)\n",
    "\n",
    "dfSadStop = removedSad.select(\"tweet\", \"tweetwords\", \"tweetnostopwords\").withColumn(\"tokens\", countTokens(col(\"tweetwords\"))).withColumn(\"notokens\", countTokens(col(\"tweetnostopwords\")))\n",
    "\n",
    "showDF(dfSadStop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis using Python package Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert each Spark Dataframe to a Pandas Dataframe. This works as-is because we are working with a small dataset. For larger datasets only convert to Pandas if data can fit in memory. From there loop over each row and get the sentiment score (anything + is postive and anything - or 0 is negative). The \"positive\" function will return true if the tweet is postive. The \"assessment\" function shows which words where used to judge and the score of each word. For more info on how the scores are calcuated: https://www.clips.uantwerpen.be/pages/pattern-en#sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pandaSad = dfSadStop.toPandas()\n",
    "movieScoreSad = 0\n",
    "countSad = 0\n",
    "numSadTweets = 0\n",
    "sadList = list()\n",
    "\n",
    "for index, row in pandaSad.iterrows():\n",
    "    if positive(row[\"tweetnostopwords\"], .1):\n",
    "        countSad = countSad + 1\n",
    "    scoreSad = sentiment(row['tweetnostopwords'])[0]\n",
    "    if scoreSad <= 0:\n",
    "        #print row['tweet']\n",
    "        #print sentiment(row['tweetnostopwords'])[0]\n",
    "        sadList.append((row['tweet'], sentiment(row[\"tweetnostopwords\"]), positive(row[\"tweetnostopwords\"]), \\\n",
    "                         sentiment(row['tweetnostopwords']).assessments))\n",
    "        movieScoreSad = scoreSad + movieScoreSad\n",
    "        \n",
    "labels = ['Original Tweet', 'Sentiment Score', 'Postive', 'Assessments']\n",
    "sadTweetScores = pandas.DataFrame.from_records(sadList, columns=labels)\n",
    "\n",
    "sadTweetScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive Tweet\n",
    "#### Also adding up all the sentiment scores of all the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandaPos = dfPosStop.toPandas()\n",
    "movieScore = 0\n",
    "countPos = 0\n",
    "poslist = list()\n",
    "\n",
    "for index, row in pandaPos.iterrows():\n",
    "    if not positive(row[\"tweetnostopwords\"]) and sentiment(row[\"tweetnostopwords\"])[0] != 0.0:\n",
    "        countPos = countPos + 1\n",
    "    score = sentiment(row['tweetnostopwords'])[0]\n",
    "    if score > 0:\n",
    "        poslist.append((row['tweet'], sentiment(row[\"tweetnostopwords\"]), positive(row[\"tweetnostopwords\"]), \\\n",
    "                         sentiment(row['tweetnostopwords']).assessments))\n",
    "        movieScore = score + movieScore\n",
    "        \n",
    "labels = ['Original Tweet', 'Sentiment Score', 'Postive', 'Assessments']\n",
    "postiveTweetScores = pandas.DataFrame.from_records(poslist, columns=labels)\n",
    "\n",
    "postiveTweetScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alright! Should I see this movie???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posrating = movieScore/(dfPos.count() - countPos)\n",
    "\n",
    "display(Markdown('**{}**  \\n{}'.format(\"Positive Rating Average Score\", posrating)))\n",
    "\n",
    "if dfSad.count() != 0:\n",
    "    sadrating = movieScoreSad/(dfSad.count() - countSad)\n",
    "else: \n",
    "    sadrating = 0\n",
    "\n",
    "display(Markdown('**{}**  \\n{}'.format(\"Negative Rating Average Score\", sadrating)))\n",
    "\n",
    "if posrating > abs(sadrating):\n",
    "    print \"People like this movie!\"\n",
    "    display(Markdown('**{}**  \\n'.format(\"People Like This Movie!\")))\n",
    "elif posrating == abs(sadrating):\n",
    "    display(Markdown('**{}**  \\n'.format(\"People are split! Take a chance!\")))\n",
    "elif posrating < abs(sadrating):\n",
    "    display(Markdown('***{}***  \\n'.format(\"People Do Not Like This Movie!\")))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is this answer what you were expecting? Either way, go back and take a look at "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
