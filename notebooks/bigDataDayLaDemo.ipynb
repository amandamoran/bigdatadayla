{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When Rotten Tomatoes Isn't Enough: Twitter Sentiment Analysis with DSE\n",
    "\n",
    "#### A demo using DataStax Enterprise Analytics, Apache Cassandra, Apache Spark, python, Jupyter Notebooks, twitter api, pattern, and sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things To Setup\n",
    "* Create a Twitter Account and get API access: https://developer.twitter.com/en/docs/basics/getting-started\n",
    "* Install DSE https://docs.datastax.com/en/install/doc/install60/installTOC.html\n",
    "* Start DSE Analytics Cluster: dse cassandra -k #Must use -k option for Analytics\n",
    "* Set and Source Twitter enviroment variables in shell you will start Jupyter from\n",
    "* CONSUMER_KEY \n",
    "* CONSUMER_SECRET \n",
    "* ACCESS_TOKEN \n",
    "* ACCESS_TOKEN_SECRET\n",
    "* Using Python 2.7\n",
    "* Using DSE Analytics 6\n",
    "* Using latest verion of Jupyter\n",
    "* Install Anaconda and Jupyter #Anaconda is not required but will make installing jupyter easier \n",
    "* Find full path to <>/dse-6.0.1/resources/spark/python/lib/pyspark.zip\n",
    "* Find full path to <>/dse-6.0.1/resources/spark/python/lib/py4j-0.10.4-src.zip\n",
    "* Start Jupyter with DSE to get all environemnt variables: dse exec jupyter notebook\n",
    "* !pip install cassandra-driver\n",
    "* !pip install tweepy \n",
    "* !pip install pattern \n",
    "* !pip install panadas\n",
    "* Counter-intuitive don't install pyspark!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add some environment variables to find dse verision of pyspark. Edit these varibles with your path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pysparkzip = \"/Users/amanda.moran/cassandra/dse-6.0.1/resources/spark/python/lib/pyspark.zip\"\n",
    "py4jzip = \"/Users/amanda.moran/cassandra/dse-6.0.1/resources/spark/python/lib/py4j-0.10.4-src.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to be able to find pyspark libaries\n",
    "import sys\n",
    "sys.path.append(pysparkzip)\n",
    "sys.path.append(py4jzip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import python packages -- all are required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import cassandra\n",
    "import pyspark\n",
    "import tweepy\n",
    "import re\n",
    "import os\n",
    "from IPython.display import display, Markdown\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer, StopWordsRemover\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pattern.en import sentiment, positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function to have nicer formatting of Spark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper for pretty formatting for Spark DataFrames\n",
    "def showDF(df, limitRows =  5, truncate = True):\n",
    "    if(truncate):\n",
    "        pandas.set_option('display.max_colwidth', 50)\n",
    "    else:\n",
    "        pandas.set_option('display.max_colwidth', -1)\n",
    "    pandas.set_option('display.max_rows', limitRows)\n",
    "    display(df.limit(limitRows).toPandas())\n",
    "    pandas.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Tables, Pulling Tweets, and Loading Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to DSE Analytics Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "\n",
    "cluster = Cluster(['127.0.0.1']) #If you have a locally installed DSE cluster\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Demo Keyspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS dseanalyticsdemo \n",
    "    WITH REPLICATION = \n",
    "    { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set keyspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.set_keyspace('dseanalyticsdemo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Movie Title variable --Change this to search for different movies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieTitle = \"missonimpossible\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveNegative = [\"pos\", \"sad\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create two tables in Cassandra for the movie title. One of negative tweets and one for positive tweets. Twitter returns a lot of information with each call but for this demo we will just utilize the twitter id (as our Primary key as it is unique) and the actual tweet. \n",
    "#### Is using twitter id the right value to distriubte by? Consider your data model when choosing your primary key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emotion in positiveNegative: \n",
    "    \n",
    "    query = \"CREATE TABLE IF NOT EXISTS movie_tweets2_%s_%s (twitterid bigint, tweet text, PRIMARY KEY (twitterid))\" % (movieTitle, emotion)\n",
    "    print query\n",
    "    session.execute(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up Search Terms for gathering tweets from Twitters API. The happy :) and sad :( face are twitter operators to find positive and negative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchTermSad = movieTitle + \" :(\"\n",
    "searchTermPos = movieTitle + \" :)\"\n",
    "\n",
    "searchTerms = [searchTermSad, searchTermPos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to CleanUp Each Tweet before if is inserted into Cassandra.\n",
    "#### Removing: \n",
    "* emojis \n",
    "* flags \n",
    "* special characters \n",
    "* URL's \n",
    "* RT (for Retweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code from: https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-\n",
    "\n",
    "def cleanUpTweet(tweet):\n",
    "    \n",
    "    emoji_pattern = re.compile(\n",
    "    u\"(\\ud83d[\\ude00-\\ude4f])|\"\n",
    "    u\"(\\ud83c[\\udf00-\\uffff])|\"  \n",
    "    u\"(\\ud83d[\\u0000-\\uddff])|\" \n",
    "    u\"(\\ud83d[\\ude80-\\udeff])|\"  \n",
    "    u\"(\\ud83c[\\udde0-\\uddff])\" \n",
    "    \"+\", flags=re.UNICODE)\n",
    "\n",
    "    removeSpecial = re.compile ('[\\n|#|@|!|.|?|,|\\\"]')\n",
    "    removeHttp = re.compile(\"http\\S+ | https\\S+\")\n",
    "    removeRetweet = re.compile(\"RT\")\n",
    "    \n",
    "    noemoji = emoji_pattern.sub(r'', tweet)\n",
    "    nospecial = removeSpecial.sub(r'', noemoji)\n",
    "    nohttp = removeHttp.sub(r'', nospecial)\n",
    "    noretweet = removeRetweet.sub(r'', nohttp)\n",
    "    \n",
    "    cleanTweet=noretweet\n",
    "    \n",
    "    return cleanTweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Required from Twitter: \n",
    "* consumer_key= ''\n",
    "* consumer_secret= ''\n",
    "* access_token=''\n",
    "* access_token_secret=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "consumer_key = os.environ['CONSUMER_KEY']\n",
    "consumer_secret = os.environ['CONSUMER_SECRET']\n",
    "\n",
    "access_token = os.environ['ACCESS_TOKEN']\n",
    "access_token_secret = os.environ['ACCESS_TOKEN_SECRET']\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This cell will pull tweets from Twitter. The max number of tweets returned for free at one time is 100. \n",
    "#### Run this code a couple of times to get more data! \n",
    "#### Once the tweets are collected, loop over the list, clean up each tweet, and then insert it into the table. A large for loops surrounds this to make one call for postive tweets and one call for negative tweets. Happy and sad face have been URL encoded. :) = \"%20%3A%29\" and :( = \"%20%3A%28\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emotion in positiveNegative:\n",
    "    print emotion\n",
    "    public_tweets = 0\n",
    "    query = \"INSERT INTO movie_tweets2_%s_%s (twitterid, tweet)\" % (movieTitle, emotion)\n",
    "    query = query + \" VALUES (%s, %s)\"\n",
    "    \n",
    "    if emotion == \"pos\":\n",
    "        searchTermPos= movieTitle + \"%20%3A%29\"\n",
    "        public_tweets = api.search(q=searchTermPos, lang=\"en\", count=\"100\")\n",
    "    if emotion == \"sad\":\n",
    "        searchTermSad= movieTitle + \"%20%3A%28\"\n",
    "        public_tweets = api.search(q=searchTermSad, lang=\"en\", count=\"100\")\n",
    "\n",
    "    for tweet in public_tweets:\n",
    "        cleanTweet = cleanUpTweet(tweet.text)\n",
    "        if \"JennyTinmouth\" not in cleanTweet:\n",
    "            session.execute(query, (tweet.id, cleanTweet))\n",
    "            print(cleanTweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do a select * on each table and verify that the tweets have been inserted into each Cassandra table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for emotion in positiveNegative:\n",
    "    print emotion\n",
    "    query = 'SELECT * FROM movie_tweets2_%s_%s limit 10' % (movieTitle, emotion)\n",
    "    rows = session.execute(query)\n",
    "    for user_row in rows:\n",
    "        print (user_row.twitterid, user_row.tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally time for Apache Spark! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a spark session that is connected to Cassandra. From there load each table into a Spark Dataframe and take a count of the number of rows in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countTokens = udf(lambda words: len(words), IntegerType())\n",
    "\n",
    "spark = SparkSession.builder.appName('demo').master(\"local\").getOrCreate()\n",
    "\n",
    "tableNamePos = \"movie_tweets2_%s_pos\" % (movieTitle.lower())\n",
    "tableNameSad = \"movie_tweets2_%s_sad\" % (movieTitle.lower())\n",
    "tablepos = spark.read.format(\"org.apache.spark.sql.cassandra\").options(table=tableNamePos, keyspace=\"dseanalyticsdemo\").load()\n",
    "tablesad = spark.read.format(\"org.apache.spark.sql.cassandra\").options(table=tableNameSad, keyspace=\"dseanalyticsdemo\").load()\n",
    "\n",
    "print \"Postive Table Count: \"\n",
    "print tablepos.count()\n",
    "print \"Negative Table Count: \"\n",
    "print tablesad.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Tokenizer to break up the sentences into indiviudals words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizerPos = Tokenizer(inputCol=\"tweet\", outputCol=\"tweetwords\")\n",
    "tokenizedPos = tokenizerPos.transform(tablepos)\n",
    "\n",
    "dfPos = tokenizedPos.select(\"tweet\", \"tweetwords\").withColumn(\"tokens\", countTokens(col(\"tweetwords\")))\n",
    "\n",
    "showDF(dfPos)\n",
    "\n",
    "tokenizerSad = Tokenizer(inputCol=\"tweet\", outputCol=\"tweetwords\")\n",
    "tokenizedSad = tokenizerSad.transform(tablesad)\n",
    "\n",
    "dfSad = tokenizedSad.select(\"tweet\", \"tweetwords\").withColumn(\"tokens\", countTokens(col(\"tweetwords\")))\n",
    "\n",
    "showDF(dfSad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using StopWordsRemover to remove all stop words. Interesting to see, people don't use many stop words with twitter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removerPos = StopWordsRemover(inputCol=\"tweetwords\", outputCol=\"tweetnostopwords\")\n",
    "removedPos = removerPos.transform(dfPos)\n",
    "\n",
    "dfPosStop = removedPos.select(\"tweet\", \"tweetwords\", \"tweetnostopwords\").withColumn(\"tokens\", countTokens(col(\"tweetwords\"))).withColumn(\"notokens\", countTokens(col(\"tweetnostopwords\")))\n",
    "\n",
    "showDF(dfPosStop)\n",
    "\n",
    "removerSad = StopWordsRemover(inputCol=\"tweetwords\", outputCol=\"tweetnostopwords\")\n",
    "removedSad = removerSad.transform(dfSad)\n",
    "\n",
    "dfSadStop = removedSad.select(\"tweet\", \"tweetwords\", \"tweetnostopwords\").withColumn(\"tokens\", countTokens(col(\"tweetwords\"))).withColumn(\"notokens\", countTokens(col(\"tweetnostopwords\")))\n",
    "\n",
    "showDF(dfSadStop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis using Python package Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert each Spark Dataframe to a Pandas Dataframe. This works as-is because we are working with a small dataset. For larger datasets only convert to Pandas if data can fit in memory. From there loop over each row and get the sentiment score (anything + is postive and anything - or 0 is negative). The \"positive\" function will return true if the tweet is postive. The \"assessment\" function shows which words where used to judge and the score of each word. For more info on how the scores are calcuated: https://www.clips.uantwerpen.be/pages/pattern-en#sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pandaSad = dfSadStop.toPandas()\n",
    "movieScoreSad = 0\n",
    "countSad = 0\n",
    "numSadTweets = 0\n",
    "sadList = list()\n",
    "\n",
    "for index, row in pandaSad.iterrows():\n",
    "    if positive(row[\"tweetnostopwords\"], .1):\n",
    "        countSad = countSad + 1\n",
    "    scoreSad = sentiment(row['tweetnostopwords'])[0]\n",
    "    if scoreSad <= 0:\n",
    "        #print row['tweet']\n",
    "        #print sentiment(row['tweetnostopwords'])[0]\n",
    "        sadList.append((row['tweet'], sentiment(row[\"tweetnostopwords\"]), positive(row[\"tweetnostopwords\"]), \\\n",
    "                         sentiment(row['tweetnostopwords']).assessments))\n",
    "        movieScoreSad = scoreSad + movieScoreSad\n",
    "        \n",
    "labels = ['Original Tweet', 'Sentiment Score', 'Postive', 'Assessments']\n",
    "sadTweetScores = pandas.DataFrame.from_records(sadList, columns=labels)\n",
    "\n",
    "sadTweetScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive Tweet\n",
    "#### Also adding up all the sentiment scores of all the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandaPos = dfPosStop.toPandas()\n",
    "movieScore = 0\n",
    "countPos = 0\n",
    "poslist = list()\n",
    "\n",
    "for index, row in pandaPos.iterrows():\n",
    "    if not positive(row[\"tweetnostopwords\"]) and sentiment(row[\"tweetnostopwords\"])[0] != 0.0:\n",
    "        countPos = countPos + 1\n",
    "    score = sentiment(row['tweetnostopwords'])[0]\n",
    "    if score > 0:\n",
    "        poslist.append((row['tweet'], sentiment(row[\"tweetnostopwords\"]), positive(row[\"tweetnostopwords\"]), \\\n",
    "                         sentiment(row['tweetnostopwords']).assessments))\n",
    "        movieScore = score + movieScore\n",
    "        \n",
    "labels = ['Original Tweet', 'Sentiment Score', 'Postive', 'Assessments']\n",
    "postiveTweetScores = pandas.DataFrame.from_records(poslist, columns=labels)\n",
    "\n",
    "postiveTweetScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alright! Should I see this movie???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posrating = movieScore/(dfPos.count() - countPos)\n",
    "\n",
    "display(Markdown('**{}**  \\n{}'.format(\"Positive Rating Average Score\", posrating)))\n",
    "\n",
    "if dfSad.count() != 0:\n",
    "    sadrating = movieScoreSad/(dfSad.count() - countSad)\n",
    "else: \n",
    "    sadrating = 0\n",
    "\n",
    "display(Markdown('**{}**  \\n{}'.format(\"Negative Rating Average Score\", sadrating)))\n",
    "\n",
    "if posrating > abs(sadrating):\n",
    "    print \"People like this movie!\"\n",
    "    display(Markdown('**{}**  \\n'.format(\"People Like This Movie!\")))\n",
    "elif posrating == abs(sadrating):\n",
    "    display(Markdown('**{}**  \\n'.format(\"People are split! Take a chance!\")))\n",
    "elif posrating < abs(sadrating):\n",
    "    display(Markdown('***{}***  \\n'.format(\"People Do Not Like This Movie!\")))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
